# awesome-LLM-Mind
## Survey
- Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review, 2024.01 [[paper]](https://arxiv.org/ftp/arxiv/papers/2401/2401.01519.pdf)
- Large Language Model for Mental Health: A Systematic Review, 2024.03 [[paper]](https://arxiv.org/ftp/arxiv/papers/2403/2403.15401.pdf)
- Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook, 2024.06 [[paper]](https://arxiv.org/pdf/2406.05984)

## Personality
- Can chatgpt assess human personalities? a general evaluation framework, 2023.06 [[paper]](https://arxiv.org/pdf/2303.01248.pdf)
- Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models, 2023.07 [[paper]](https://arxiv.org/pdf/2307.16180.pdf) [[code]](https://github.com/HarderThenHarder/transformers_tasks/tree/main/LLM/llms_mbti)
- Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models, 2023.09 [[paper]](https://arxiv.org/pdf/2309.08163.pdf)
- Does Role-Playing Chatbots Capture the Character Personalities? Assessing Personality Traits for Role-Playing Chatbots, 2023.10 [[paper]](https://arxiv.org/pdf/2310.17976.pdf) [[code]](https://github.com/LC1332/Chat-Haruhi-Suzumiya)
- Editing Personality for LLMs, 2023.10 [[paper]](https://arxiv.org/pdf/2310.02168.pdf)
- Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons, 2023.10 [[paper]](https://arxiv.org/pdf/2310.16582.pdf)
- You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments, 2023.11 [[paper]](https://arxiv.org/pdf/2311.09718.pdf)
- On the steerability of large language models toward data-driven personas, 2023.11 [[paper]](https://arxiv.org/pdf/2311.04978.pdf)
- Do personality tests generalize to Large Language Models?, 2023.11 [[paper]](https://arxiv.org/pdf/2311.05297.pdf)
- Is Cognition and Action Consistent or Not: Investigating Large Language Model’s Personality, 2024.02 [[paper]](https://arxiv.org/pdf/2402.14679.pdf)
- Stick to your Role! Stability of Personal Values Expressed in Large Language Models, 2024.02 [[paper]](https://arxiv.org/pdf/2402.14846.pdf)
- On the Decision-Making Abilities in Role-Playing using Large Language Models, 2024.02 [[paper]](https://arxiv.org/pdf/2402.18807.pdf)
- Risk and prosocial behavioural cues elicit human-like response patterns from AI chatbots, 2024.03 [[paper]](https://www.nature.com/articles/s41598-024-55949-y)

## Mental Health of LLM
- Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective, 2022.12 [[paper]](https://arxiv.org/pdf/2212.10529.pdf)
- Towards Healthy AI: Large Language Models Need Therapists Too, 2023.04 [[paper]](https://arxiv.org/pdf/2304.00416.pdf)
- Inducing anxiety in large language models increases exploration and bias, 2023.04 [[paper]](https://arxiv.org/pdf/2304.11111.pdf)
- Cognitive Effects in Large Language Model, 2023.08 [[paper]](https://arxiv.org/pdf/2308.14337.pdf)
- Risk and prosocial behavioural cues elicit human-like response patterns from AI chatbots, 2024.04 [[paper]](https://www.nature.com/articles/s41598-024-55949-y)
- ESCoT: Towards Interpretable Emotional Support Dialogue Systems, 2024.06 [[paper]](https://arxiv.org/pdf/2406.10960)

## Bias of LLM
- The high dimensional psychological profile and cultural bias of ChatGPT, 2024.05 [[paper]](https://arxiv.org/pdf/2405.03387)
- Quite Good, but Not Enough: Nationality Bias in Large Language Models - A Case Study of ChatGPT, 2024.05 [[paper]](https://arxiv.org/pdf/2405.06996)
- Understanding Intrinsic Socioeconomic Biases in Large Language Models, 2024.05 [[paper]](https://arxiv.org/pdf/2405.18662)
- Uncovering Bias in Large Vision-Language Models at Scale with Counterfactuals, 2024.05 [[paper]](https://arxiv.org/pdf/2405.20152)
- Ask LLMs Directly, “What shapes your bias? ”: Measuring Social Bias in Large Language Models, 2024.06 [[paper]](https://arxiv.org/pdf/2406.04064)
- Underneath the Numbers: Quantitative and Qualitative Gender Fairness in LLMs for Depression Prediction, 2024.06 [[paper]](https://arxiv.org/pdf/2406.08183)
- Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination, 2024.06 [[paper]](https://arxiv.org/pdf/2406.08818)
- Do Large Language Models Discriminate in Hiring Decisions on the Basis of Race, Ethnicity, and Gender?, 2024.06 [[paper]](https://arxiv.org/pdf/2406.10486)

# Ethics
- Deconstructing The Ethics of Large Language Models from Long-standing Issues to New-emerging Dilemmas, 2024.06 [[paper]](https://arxiv.org/pdf/2406.05392)


## Value
- From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models, 2023.10 [[paper]](https://arxiv.org/pdf/2310.17857.pdf) [[code]](https://arxiv.org/pdf/2310.17857.pdf)
- Global Data Constraints: Ethical and Effectiveness Challenges in Large Language Model, 2024.06 [[paper]](https://arxiv.org/pdf/2406.11214)


## Culture
- The Cultural Psychology of Large Language Models: Is ChatGPT a Holistic or Analytic Thinker?, 2023.08 [[paper]](https://arxiv.org/ftp/arxiv/papers/2308/2308.14242.pdf)
- How Culturally Aware are Vision-Language Models?, 2024.05 [[paper]](https://arxiv.org/pdf/2405.17475)

## Agent
- LLM Agents for Psychology: A Study on Gamified Assessments, 2024.02 [[paper]](https://arxiv.org/pdf/2402.12326.pdf)
- Advancing Social Intelligence in AI Agents: Technical Challenges and Open Questions, 2024.04 [[paper]](https://arxiv.org/pdf/2404.11023.pdf)

## Moral 
- Evaluating the Moral Beliefs Encoded in LLMs, 2023.07 [[paper]](https://arxiv.org/pdf/2307.14324.pdf) [[code]](https://github.com/ninodimontalcino/moralchoice)
- Exploring ChatGPT’s Empathic Abilities, 2023.08 [[paper]](https://arxiv.org/pdf/2308.03527.pdf)
- MoCa: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks, 2023.10 [[paper]](https://arxiv.org/pdf/2310.19677.pdf)
- Is ChatGPT More Empathetic than Humans?, 2024.03 [[paper]](https://arxiv.org/pdf/2403.05572.pdf) [[code]](https://github.com/anuradha1992/llm-empathy-evaluation)
- Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs, 2024.05 [[paper]](https://arxiv.org/pdf/2405.12933)
- Exploring and steering the moral compass of Large Language Models, 2024.05 [[paper]](https://arxiv.org/pdf/2405.17345)
- HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs, 2024.05 [[paper]](https://arxiv.org/pdf/2405.17633)
- The ethical situation of DALL-E 2, 2024.05 [[paper]](https://arxiv.org/pdf/2405.19176)
- Do Language Models Understand Morality? Towards a Robust Detection of Moral Content, 2024.06 [[paper]](https://arxiv.org/pdf/2406.04143)
- Are Large Language Models More Empathetic than Humans?, 2024.06 [[paper]](https://arxiv.org/pdf/2406.05063)

## LLM and Human
- Can AI language models replace human participants?, 2023.07 [[paper]](https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(23)00098-0)
- Do you trust ChatGPTs? Effects of the ethical and quality issues of generative AI on travel decisions, 2023.09 [[paper]](https://www.tandfonline.com/doi/full/10.1080/10548408.2023.2293006)
- AI can help people feel heard, but an AI label diminishes this impact, 2024.01 [[paper]](https://www.pnas.org/doi/abs/10.1073/pnas.2319112121)
- Would you trust an AI team member? Team trust in human–AI teams, 2024.03 [[paper]](https://bpspsychub.onlinelibrary.wiley.com/doi/epdf/10.1111/joop.12504)
- Can a Hallucinating Model help in Reducing Human “Hallucination”?, 2024.05 [[paper]](https://arxiv.org/pdf/2405.00843)
- Testing theory of mind in large language models and humans, 2024.05 [[paper]](https://www.nature.com/articles/s41562-024-01882-z)
- Can AI Understand Human Personality? - Comparing Human Experts and AI Systems at Predicting Personality Correlations, 2024.06 [[paper]](https://arxiv.org/pdf/2406.08170)
- Can Machines Resonate with Humans? Evaluating the Emotional and Empathic Comprehension of LMs, 2024.06 [[paper]](https://arxiv.org/pdf/2406.11250)


## Experiment
- Artificial cognition: How experimental psychology can help generate explainable artificial intelligence, 2020.11 [[paper]](https://link.springer.com/article/10.3758/s13423-020-01825-5)
- We Need to Talk About Mechanical Turk: What 22,989 Hypothesis Tests Tell Us About Publication Bias and P-Hacking in Online Experiments, 2022.08 [[paper]](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4188289)
- Are Large Language Models Chameleons?, 2024.05 [[paper]](https://arxiv.org/pdf/2405.19323)
- LLM Questionnaire Completion for Automatic Psychiatric Assessm, 2024.06 [[paper]](https://arxiv.org/pdf/2406.06636)

## Evaluation
- Supervised Learning and Large Language Model Benchmarks on Mental Health Datasets: Cognitive Distortions and Suicidal Risks in Chinese Social Media, 2023.09 [[paper]](https://arxiv.org/pdf/2309.03564.pdf) [[code]](https://github.com/HongzhiQ/SupervisedVsLLM-EfficacyEval)
- CogBench: a large language model walks into a psychology lab, 2024.02 [[paper]](https://arxiv.org/pdf/2402.18225.pdf) [[code]](https://github.com/juliancodaforno/CogBench)
- GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing, 2024.03 [[paper]](https://arxiv.org/pdf/2403.05916.pdf) [[code]](https://github.com/LuPaoPao/GPT4Affectivity)
- Evaluating and Inducing Personality in Pre-trained Language Models, 2023.09 [[paper]](https://arxiv.org/pdf/2206.07550.pdf) [[project]](https://sites.google.com/view/machinepersonality)

## Turning by Psychology 
- Turning large language models into cognitive models, 2023.06 [[paper]](https://arxiv.org/pdf/2306.03917.pdf)
- NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli, 2024.05 [[paper]](https://arxiv.org/pdf/2405.02814)


## Bechmark
- Emotionally numb or empathetic? evaluating how llms feel using emotionbench, 2023.08 [[paper]](https://arxiv.org/pdf/2308.03656.pdf)[[code]](https://github.com/CUHK-ARISE/EmotionBench)
- Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench, 2023.10 [[paper]](https://arxiv.org/pdf/2310.01386.pdf) [[code]](https://github.com/CUHK-ARISE/PsychoBench)
- CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models, 2023.11 [[paper]](https://arxiv.org/pdf/2311.16421.pdf) [[code]](https://github.com/astrodrew/CDEval)
- CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations, 2024.05 [[paper]](https://arxiv.org/pdf/2405.10212)
- MentalQA: An Annotated Arabic Corpus for Questions and Answers of Mental Healthcare, 2024.05 [[paper]](https://arxiv.org/pdf/2405.12619)
- CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling, 2024.05 [[paper]](https://arxiv.org/pdf/2405.16433)
- Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions,  2024.05 [[paper]](https://arxiv.org/pdf/2405.19088)
- ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models, 2024.06 [[paper]](https://arxiv.org/pdf/2406.04214)
- MoralBench: Moral Evaluation of LLMs, 2024.06 [[paper]](https://arxiv.org/pdf/2406.04428)
- MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs, 2024.06 [[paper]](https://arxiv.org/pdf/2406.07243)

## Mental Health Applications
- In principle obstacles for empathic AI: why we can’t replace human empathy in healthcare, 2021.05 [[ppaer]](https://link.springer.com/article/10.1007/s00146-021-01230-z)
- A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement, 2023.10 [[paper]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10601652/)
- Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects, 2023.12 [[paper]](https://arxiv.org/pdf/2312.04578.pdf)
- Influencing human–AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness, 2023.10 [[paper]](https://www.nature.com/articles/s42256-023-00720-7)
- Rethinking Large Language Models in Mental Health Applications, 2023.11 [[paper]](https://arxiv.org/pdf/2311.11267.pdf)
- Challenges of Large Language Models for Mental Health Counseling, 2023.11 [[paper]](https://arxiv.org/pdf/2311.11267.pdf)
- Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects, 2023.12 [[paper]](https://arxiv.org/pdf/2312.04578.pdf)
- A Dual-Prompting for Interpretable Mental Health Language Models, 2024.02 [[paper]](https://arxiv.org/pdf/2402.14854.pdf)
- HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy, 2024.03 [[paper]](https://arxiv.org/pdf/2403.05574.pdf)
- CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering, 2024.03 [[paper]](https://arxiv.org/pdf/2403.16008.pdf)
- AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts, 2024.04 [[paper]](https://arxiv.org/pdf/2404.11449.pdf)
- Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support, 2024.05 [[paper]](https://arxiv.org/pdf/2405.09300)
- Can AI Relate: Testing Large Language Model Response for Mental Health Support, 2024.05 [[paper]](https://arxiv.org/pdf/2405.12021)
- Automating PTSD Diagnostics in Clinical Interviews: Leveraging Large Language Models for Trauma Assessments, 2024.05 [[paper]](https://arxiv.org/pdf/2405.11178)
- Are Large Language Models Moral Hypocrites? A Study Based on Moral Foundations, 2024.05 [[paper]](https://arxiv.org/pdf/2405.11100)
- PATIENT-Ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals, 2024.05 [[paper]](https://arxiv.org/pdf/2405.19660)
- CASE: Curricular Data Pre-training for Building Generative and Discriminative Assistive Psychology Expert Models, 2024.06 [[paper]](https://arxiv.org/pdf/2406.00314)
- Enhancing Psychotherapy Counseling: A Data Augmentation Pipeline Leveraging Large Language Models for Counseling Conversations, 2024.06 [[paper]](https://arxiv.org/pdf/2406.08718)
- We Care: Multimodal Depression Detection and Knowledge Infused Mental Health Therapeutic Response Generation, 2024.06 [[paper]](https://arxiv.org/pdf/2406.10561)

## Others
- Thinking Fast and Slow in Large Language Models, 2022.12 [[paper]](https://arxiv.org/pdf/2212.05206)
- Using cognitive psychology to understand GPT-3, 2023.02 [[paper]](https://www.pnas.org/doi/abs/10.1073/pnas.2218523120)
- Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Method, 2023.03 [[paper]](https://arxiv.org/ftp/arxiv/papers/2303/2303.13988.pdf)
- Large language models can infer psychological dispositions of social media users, 2023.09 [[paper]](https://arxiv.org/pdf/2309.08631)
- Using large language models in psychology, 2023.10 [[paper]](https://www.nature.com/articles/s44159-023-00241-5)
- Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph, 2024.02 [[paper]](https://arxiv.org/pdf/2402.14424.pdf)
- Towards a Psychology of Machines: Large Language Models Predict Human Memory, 2024.03 [[paper]](https://arxiv.org/pdf/2403.05152.pdf)
- The Psychosocial Impacts of Generative AI Harms, 2024.05 [[paper]](https://arxiv.org/pdf/2405.01740)
- Limited ability of LLMs to simulate human psychological behaviours: a psychometric analysis, 2024.05 [[paper]](https://arxiv.org/pdf/2405.07248)
- How does ChatGPT 'think'? Psychology and neuroscience crack open AI large language models, 2024.05 [[paper]](https://pubmed.ncbi.nlm.nih.gov/38745024/)
- LLMs achieve adult human performance on higher-order theory of mind tasks, 2024.05 [[paper]](https://arxiv.org/pdf/2405.18870)
- A Philosophical Introduction to Language Models Part II: The Way Forward, 2024.05 [[paper]](https://arxiv.org/pdf/2405.03207)
- Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models, 2024.06 [[paper]](https://arxiv.org/pdf/2406.03882)
- BLSP-Emo: Towards Empathetic Large Speech-Language Models, 2024.06 [[paper]](https://arxiv.org/pdf/2406.03872)
- Deception abilities emerged in large language models， 2024.06 [paper](https://www.pnas.org/doi/abs/10.1073/pnas.2317967121)

